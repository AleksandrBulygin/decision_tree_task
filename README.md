# Decision Tree
Проект с реализацией алгоритма классификации на основе дерева принятия решений
и случайного леса

Выполнил: Булыгин Александр

В результате получены следующие зависимости метрики f1 от параметров обучения:

	-глубина дерева;
	
	-минимальное количество экземпляров в листе.

Данные зависимости представлены на следующих изображениях

![alt text](plots/Figure_2022-04-13_212643_(0).png "Рисунок 1")

![alt text](plots/Figure_2022-04-13_212643_(1).png "Рисунок 2")

![alt text](plots/Figure_2022-04-13_212643_(2).png "Рисунок 3")

![alt text](plots/Figure_2022-04-13_212643_(3).png "Рисунок 4")

![alt text](plots/Figure_2022-04-13_212643_(4).png "Рисунок 5")

![alt text](plots/Figure_2022-04-13_212643_(5).png "Рисунок 6")

В качестве оптимальных выбиралось среднее значение оптимального параметра

для среди оптимальных параметров для каждого класса.

Метрики f1 для DT, RF и реализации SciKit Learn:

```Python 
	f1 для каждого класса:  				   [0.27272727 0.86614173 0.87128713]
	f1 для каждого класса после классификации случайным лесом: [0.4        0.87037037 0.8034188 ]
	f1 для дерева, созданного из SkLearn:  			   [0.         0.87096774 0.88461538]
```

Плохое качество классификации первого класса обусловлено тем, что во всём

датасете данный класс представлен 8% экземпляров.